---
title: "M9: Forecast Accuracy"
author: "Luana Lima"
date: "03/12/2021"
output: pdf_document
always_allow_html: true
editor_options: 
  chunk_output_type: inline
---

## Setting R code chunk options

First R code chunk is used for setting the options for all R code chunks. The choice echo=TRUE means both code and output will appear on report, include = FALSE neither code nor output is printed.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=80), tidy=FALSE) 
```

## Loading packages and initializing

Second R code chunk is for loading packages. By setting message = FALSE, the code will appear but not the output.

```{r package, message=FALSE}
library(lubridate)
library(ggplot2)
library(forecast)  
#library(Kendall)
library(tseries)
#library(outliers)
library(tidyverse)
library(smooth)

#New package for M9 to assist with tables
#install.packages("kableExtra")
library(kableExtra)

```

## Importing data

For this module we will continue to work with the electricity retail price in US dataset from the U.S. Energy Information Administration. You may download [here][[https://www.eia.gov/electricity/data/browser/\#/topic/7?agg=2,0,1&geo=g&freq=M%2013:41:41%20GMT-0500%20(EST)](https://www.eia.gov/electricity/data/browser/#/topic/7?agg=2,0,1&geo=g&freq=M%2013:41:41%20GMT-0500%20(EST)){.uri}]. But this week we will work with the all.sectors column instead of residential price.

```{r}

#Importing time series data from text file#
electricity_price <- read.csv(
  file="./Data/Average_retail_price_of_electricity_United_States_monthly.csv",
  header=TRUE,
  skip=4)

#Inspect data
head(electricity_price)
nvar <- ncol(electricity_price) - 1
nobs <- nrow(electricity_price)

#Preparing the data - create date object and rename columns
electricity_price_processed <-
  electricity_price %>%
  mutate( Month = my(Month) ) %>% 
  rename( All.sectors = all.sectors.cents.per.kilowatthour ) %>% 
  rename( Residential = residential.cents.per.kilowatthour ) %>% 
  rename( Commercial = commercial.cents.per.kilowatthour ) %>% 
  rename( Industrial = industrial.cents.per.kilowatthour ) %>% 
  arrange( Month )

#head(electricity_price_processed)
summary(electricity_price_processed)

#No NAs so we don't need to worry about missing values

```

## Transforming data into time series object

Many of the functions we will use require a time series object. You can transform your data in a time series using the function *ts()*.

```{r}
ts_electricity_price <- ts(
  electricity_price_processed[,2:(nvar+1)],
  start=c(year(electricity_price_processed$Month[1]),month(electricity_price_processed$Month[1])),
  frequency=12) 

#note that we are only transforming columns with electricity price, not the date columns  
head(ts_electricity_price,15)
tail(ts_electricity_price,15)

```

## Initial Plots

```{r}
TS_Plot <- 
  ggplot(electricity_price_processed, aes(x=Month, y=All.sectors)) +
      geom_line()
plot(TS_Plot)

#ACF and PACF plots
par(mfrow=c(1,2))
ACF_Plot <- Acf(electricity_price_processed$All.sectors, lag = 40, plot = TRUE,main="")
PACF_Plot <- Pacf(electricity_price_processed$All.sectors, lag = 40, plot = TRUE,main="")
par(mfrow=c(1,1))
```

## Decomposing the time series

The plots from the previous section show the data has a seasonal component. Since we are working with non-seasonal ARIMA, we need to decompose the series and eliminate the seasonality.

```{r}
#Using R decompose function
decompose_allsectors_price <- decompose(ts_electricity_price[,"All.sectors"],"additive")
plot(decompose_allsectors_price)

#The ACF plot show a slow decay which is a sign of non-stationarity.
#Creating non-seasonal residential price time series because some models can't handle seasonality
deseasonal_allsectors_price <- seasadj(decompose_allsectors_price)  
```

## Fitting Models to the original (seasonal) series

On M8 we tried several models for both seasonal and deseasonal electricity price series. This week the goal is to chekc accuracy of those models. Let's start by looking at residual plots and AIC to check how the models represent the historical prices.

### Model 1: Arithmetic mean
```{r}
MEAN_seas <- meanf(y = ts_electricity_price[,"All.sectors"], h = 12)
checkresiduals(MEAN_seas)
```
Note a clear trend on residuals series, showing that the mean is not a good to model the trend component. And aside from trend the seasonal component is also not being modeled.

### Model 2: Seasonal naive
```{r}
SNAIVE_seas <- snaive(ts_electricity_price[,"All.sectors"], h=12)
checkresiduals(SNAIVE_seas)
```
The residuals for the seasonal naive don't seem to have a strong trend. Because it repeats the observations that happen in a previous seasonal lag (in this case one year ago), the seasonal naive is able to model the trend and seasonal component. But the residuals series show a strong autoregressive component which is also not desired.

### Model 3: SARIMA
```{r}
SARIMA_autofit <- auto.arima(ts_electricity_price[,"All.sectors"])
checkresiduals(SARIMA_autofit)
```
This is by far the best fit. Notice the residual series seems to be random and ACF shows no significant self correlation.


## Model Performance for forecasting 12 steps ahead

We are done with backward-looking assessment. SARIMA seems to be a good fit for our data. In a real world, you wouldn't even move further with the arithmetic mean or the seasonal naive method. Since they fail the backward-looking assessment, it's known that they will lead to poor forecast. But just as an exercise we will also perform a forward-looking assessment for all three model.

### Function accuracy() from package `forecast`

The function accuracy() will return performance measures. It takes the main arguments:

**object** object of class forecast, or numerical values containing forecasts. **x** numerical vector containing observed values (optional).

If **x** is not provided the function will return performance measures for trainign set, i.e., based on historical data it will compare observed and fitted values.

The measures calculated are:

**ME:** Mean Error **RMSE:** Root Mean Squared Error **MAE:** Mean Absolute Error **MPE:** Mean Percentage Error **MAPE:** Mean Absolute Percentage Error **MASE:** Mean Absolute Scaled Error **ACF1:** Autocorrelation of errors at lag 1

### Checking accuracy of the three models

```{r}
#Model 1: Arithmetic mean
MEAN_scores <- accuracy(MEAN_seas)  #store the performance metrics
plot(MEAN_seas)  #plot forecasts

#Model 2: Seasonal naive 
SNAIVE_scores <- accuracy(SNAIVE_seas)
plot(SNAIVE_seas)

# Model 3:  SARIMA 
#remember auto.arima does not call the forecast() internally so we need one more step
SARIMA_for <- forecast(SARIMA_autofit,h=12)
SARIMA_scores <- accuracy(SARIMA_for)
plot(SARIMA_for)

```

### Compare performance metrics

Now we will create a data frame that combines performance metrics for all the three models. You can choose one metric to help you choose among models. For example let's say we want the model with lowest RMSE.

````{r}
#create data frame
seas_scores <- as.data.frame(rbind(MEAN_scores, SNAIVE_scores, SARIMA_scores))
row.names(seas_scores) <- c("MEAN", "SNAIVE","SARIMA")

#choose model with lowest RMSE
best_model_index <- which.min(seas_scores[,"RMSE"])
cat("The best model by RMSE is:", row.names(seas_scores[best_model_index,]))                       
                            
```

SARIMA was the best fit for the seasonal data. If you want generate a table to compare model accuracy and help visualize the results here is a suggestion on how to include a table on your Rmd report. You can use the `kable_styling(latex_options="striped")` to highlight the model that leads to minimum RMSE.

```{r}


kbl(seas_scores, 
      caption = "Forecast Accuracy for Seasonal Data",
      digits = array(5,ncol(seas_scores))) %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  #highlight model with lowest RMSE
  kable_styling(latex_options="striped", stripe_index = which.min(seas_scores[,"RMSE"]))
```

